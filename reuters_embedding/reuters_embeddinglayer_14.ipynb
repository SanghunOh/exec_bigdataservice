{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reuters_embeddinglayer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPwDpOcqSC/kmL32OMfPqu4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZxj2_LhXYtC"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmvF7trRZJQy",
        "outputId": "eb20db71-d4ce-47db-be53-11899515c0d4"
      },
      "source": [
        "(x_train, y_train), (x_test,y_test) = tf.keras.datasets.reuters.load_data(num_words=10000)\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/reuters.py:143: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/reuters.py:144: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8982,), (8982,), (2246,), (2246,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRp031ipZmVN",
        "outputId": "573a2fd1-21d5-4224-8cca-2ae9c4d2f2ef"
      },
      "source": [
        "print(x_train[3])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 4, 686, 867, 558, 4, 37, 38, 309, 2276, 465, 893, 3541, 114, 2902, 69, 312, 35, 15, 7, 335, 1679, 21, 25, 3675, 2, 3498, 58, 69, 68, 493, 5, 25, 465, 377, 2430, 4, 293, 1172, 739, 4379, 8, 7, 1510, 1131, 13, 899, 6, 4, 990, 309, 415, 4519, 6920, 645, 3916, 791, 5, 4379, 75, 8, 24, 10, 1311, 4677, 5, 344, 756, 7, 2, 231, 9691, 2603, 1413, 43, 509, 43, 68, 327, 5, 2, 3498, 297, 638, 73, 430, 22, 4, 580, 7, 48, 41, 30, 2, 136, 4, 344, 298, 4, 580, 40, 344, 5078, 2, 291, 1488, 10, 3148, 5, 231, 6250, 1308, 5, 8250, 7043, 21, 2, 1622, 990, 309, 415, 265, 5992, 8945, 1149, 9118, 2, 4, 344, 9691, 756, 3729, 2, 4667, 2, 3249, 28, 10, 2190, 24, 77, 41, 682, 10, 4851, 2048, 7, 4, 5540, 2926, 1598, 22, 370, 5954, 7541, 5, 54, 5232, 1685, 2916, 10, 1571, 946, 60, 51, 3249, 5249, 4, 73, 2135, 669, 4, 580, 64, 10, 4280, 6, 2, 25, 482, 35, 150, 377, 2430, 7, 10, 2, 836, 2, 4730, 6920, 5, 4379, 2, 2, 3541, 8, 4, 344, 291, 2, 298, 4228, 6, 2223, 24, 2, 41, 343, 430, 210, 6, 3498, 297, 64, 10, 2281, 455, 5, 7003, 125, 222, 17, 12]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qDCJZBZZuhy",
        "outputId": "3295e367-92d2-4ab2-d6f2-837e40e1c0e7"
      },
      "source": [
        "import numpy as np\n",
        "np.unique(y_train)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
              "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb3E09RBZ1F7"
      },
      "source": [
        "word_dic = tf.keras.datasets.reuters.get_word_index()\n",
        "print(word_dic)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1j6BoXofoBt"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHfKm7JxaY42"
      },
      "source": [
        "invert_word_index = dict()\n",
        "for (key,value) in word_dic.items():\n",
        "  invert_word_index[value] = key\n",
        "print(invert_word_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXC3GxdNbK8J"
      },
      "source": [
        "def f_decode_string(x_data):\n",
        "  decode_str = str()\n",
        "  for num in x_data:\n",
        "    #print(i, invert_word_index[num])\n",
        "    decode_str = decode_str + invert_word_index[num] + ' '\n",
        "\n",
        "  return decode_str"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "ARLU1lrPbikA",
        "outputId": "a2119db7-d7e8-4495-94ea-17fcd0d9160c"
      },
      "source": [
        "f_decode_string(x_train[30])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'the in has would seven time mln asked has would owns domestic may said profits on been said national and slash 1988 on been said friday textile and warrants 3 before on been said bpd and 157 in national it slash trading carryforward on been said particularly hostile call 3 industrial on been said fears hostile call 3 cts it believe 28 in after london continued 2 in friday textile may and warrants trading vessels on been it believe 28 in but 18 spending 3 existing on been 28 in after london spending in time mln in before on been said bpd may and 157 or it believe 28 in but 18 spending 1 mln in continued 2 it national instruments prior from bpd development from 3 friday textile members from pct dlrs '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_lQWga0jtLT"
      },
      "source": [
        "# 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vqvjXOacQUV",
        "outputId": "2a87d1b8-dc93-4054-8ac8-e8968f4eef82"
      },
      "source": [
        "len(x_train[0]), len(x_train[50]), len(x_train[500]), len(x_train[1000]), len(x_train[3])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(87, 118, 170, 626, 224)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9HEcYqmcZIg",
        "outputId": "a4ad3275-8770-46f6-e544-97c753353027"
      },
      "source": [
        "pad_x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=500)\n",
        "len(pad_x_train[1000]), pad_x_train[1000]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, array([   7,    2,    8,  790,  680, 1935,  756,   52,   29,  137,    2,\n",
              "         530,   30,  524,   27,    4,  637,  192, 2392,  188,  181,  495,\n",
              "        6108,    9,    4,  248,  495, 5143,  739,  332,   57,   85, 2847,\n",
              "          27,    4, 1544,   24, 2349,  756,   41, 1521,   10, 2666,    5,\n",
              "        2392,  291, 1032,   50,   40,   85,    7,  642,  224,    2, 1237,\n",
              "        2563,    2,    4,  291, 1032,    6, 4208,  724, 2277,    7,  809,\n",
              "           6, 1586,    4,  295, 3255,  969, 1152,    5, 2830,   16,  495,\n",
              "         199,    8,  224,    4, 1077,    5, 1049,    4,  495, 1032,   40,\n",
              "         923, 2435,  893,    6,  196, 1147, 3852,  732,  962,  282,   21,\n",
              "          10, 1312,  503,   51,  893, 6250,  391,   45, 1940,    6,  507,\n",
              "           2, 2701,  269,   43, 1091,    9, 1474,  227,  801,  227,    9,\n",
              "         128, 3576,  577,  910, 1610,  227,  986,  128,  101,  516,    7,\n",
              "         127,  689,    9, 1458,    2, 4625,    5,  128,  101,    2,    4,\n",
              "         199,    8,    4,  673,  347,    5,    4,   37,   38,   37,  412,\n",
              "         795, 3395,    7,    2,  164, 1528, 4625,    5, 1199, 1475,    9,\n",
              "          13, 8100,    7, 5537, 1062, 2669,   21,  227, 3576,   97,  128,\n",
              "        3576,   51,  657,  107,  437,  495, 1237, 1541,   31,  126,    5,\n",
              "           4,    2,    5, 3576,   77,    2,   21,  700,    6, 1310,  567,\n",
              "        1805, 7734,   13,    4, 1199,   37,   38,  496,  795,  439,   10,\n",
              "        5947, 1040,    5,    2,   13, 6812,    4, 5109,    5,  464, 1085,\n",
              "           7, 3576, 1760, 5979, 1199,   23, 9900,   27,    4,  231,    2,\n",
              "        1500,  185,    2,  631,    2,   52,   23,    4,  345,  528,   76,\n",
              "           6,   76,  347,   51,  437, 1237,   55,  328,    6,  888,   52,\n",
              "         389,  762, 2828,    9,    6,  623,  125, 4573, 1308,   21,   10,\n",
              "        2803,    5,  893, 5968, 4029,  519,    6,    4,    2,    5,    4,\n",
              "        3498, 1085,    4,  199,    8,    4,    2,   75,  328,  107,  893,\n",
              "        6250,   55, 1158,    6,  439, 2435,  221, 8996,   55, 2473,   13,\n",
              "         396, 1237,  119,   20,   13,  260,  171,  132,   20,   13,  127,\n",
              "         171,    9,  251,   20,   13,  100,  127,    9,  358,   60, 3498,\n",
              "          10,  226,    2,   23,   24,    4,   95, 3312,    2,    5,  732,\n",
              "        1261,    7,    4,   37,   38,    9,    4,   37,  412,   91,  592,\n",
              "         437,  171,   28,   10, 1136, 8497,    4,  199,    8, 9935,    2,\n",
              "         483,   75, 1536,    4,  489,    5,   10, 4991,    5,    4,   37,\n",
              "          38,   37,  412,  795,  114,  550, 1740,    4, 1354,    5,    4,\n",
              "          37,   38,    9,  496, 1237,    4,  199,    8,   68, 5886,   13,\n",
              "        7126,   60, 1034,    8,   10,  295, 3942,  127,  108, 1474,  587,\n",
              "         114,   13, 8100,   30, 1410,  136,    4,  314, 1935,   43,   10,\n",
              "        2384,  227, 2635,  618,    4, 1544,   24,    4, 1199,   91,   30,\n",
              "        3664, 1528,  700,   73, 2135,   33, 1575,  127,  171,  483,   34,\n",
              "        3007,  509,   57, 2197,    6,  382,  323, 1969,    9, 2265,   13,\n",
              "          10,  382,  495, 5834,  117,    4,   54,   78,  206,    7,  809,\n",
              "           6,  616, 4567,  682, 6679,   51,   43,  125,  732,  244,   23,\n",
              "        2482,  808, 2491,  893, 6250,   33, 3675,    2,  127, 2435, 3959,\n",
              "           5, 1937, 1171,    7,    4,  815,  218,    5,  227, 3576,  107,\n",
              "          77,   55, 1067,    6,  439,   95, 1101,    7,    4,  567, 1805,\n",
              "           4,  199,  152,   17,   12], dtype=int32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJQljw2hcg6o",
        "outputId": "9dd0053a-feb2-4b4a-ff6d-c8f2426376bc"
      },
      "source": [
        "np.unique(y_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
              "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnYvp-pfjpKj"
      },
      "source": [
        "# make model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii4AZ0kfcl6w"
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Embedding(input_dim=10000, output_dim=24, input_length=500)) # inputlayer\n",
        "model.add(tf.keras.layers.Flatten()) # hidden layer\n",
        "model.add(tf.keras.layers.Dense(46, activation='softmax')) # output layer\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc']) # gadget"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzRg4RSLdJZy",
        "outputId": "97308295-2423-4a61-8161-7307156fb04c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 500, 24)           240000    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 46)                552046    \n",
            "=================================================================\n",
            "Total params: 792,046\n",
            "Trainable params: 792,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1w7ZL82dKGd",
        "outputId": "0210e9b7-d105-4e04-8223-6b3456e48588"
      },
      "source": [
        "hist = model.fit(pad_x_train, y_train, epochs=50, validation_split=0.3, batch_size=32)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "197/197 [==============================] - 3s 13ms/step - loss: 2.1221 - acc: 0.4552 - val_loss: 1.6946 - val_acc: 0.5692\n",
            "Epoch 2/50\n",
            "197/197 [==============================] - 3s 13ms/step - loss: 1.3409 - acc: 0.6669 - val_loss: 1.4234 - val_acc: 0.6553\n",
            "Epoch 3/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.7465 - acc: 0.8389 - val_loss: 1.3125 - val_acc: 0.6924\n",
            "Epoch 4/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.4223 - acc: 0.9162 - val_loss: 1.3118 - val_acc: 0.6983\n",
            "Epoch 5/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.2750 - acc: 0.9502 - val_loss: 1.3131 - val_acc: 0.7065\n",
            "Epoch 6/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.1994 - acc: 0.9612 - val_loss: 1.3613 - val_acc: 0.6980\n",
            "Epoch 7/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.1664 - acc: 0.9652 - val_loss: 1.3854 - val_acc: 0.6983\n",
            "Epoch 8/50\n",
            "197/197 [==============================] - 3s 13ms/step - loss: 0.1503 - acc: 0.9653 - val_loss: 1.3875 - val_acc: 0.7017\n",
            "Epoch 9/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.1406 - acc: 0.9655 - val_loss: 1.4370 - val_acc: 0.6972\n",
            "Epoch 10/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.1276 - acc: 0.9676 - val_loss: 1.5276 - val_acc: 0.6865\n",
            "Epoch 11/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.1289 - acc: 0.9671 - val_loss: 1.4738 - val_acc: 0.6987\n",
            "Epoch 12/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.1222 - acc: 0.9671 - val_loss: 1.4422 - val_acc: 0.6998\n",
            "Epoch 13/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.1155 - acc: 0.9671 - val_loss: 1.4481 - val_acc: 0.7017\n",
            "Epoch 14/50\n",
            "197/197 [==============================] - 2s 11ms/step - loss: 0.1187 - acc: 0.9671 - val_loss: 1.4606 - val_acc: 0.6991\n",
            "Epoch 15/50\n",
            "197/197 [==============================] - 2s 11ms/step - loss: 0.1175 - acc: 0.9671 - val_loss: 1.4959 - val_acc: 0.6987\n",
            "Epoch 16/50\n",
            "197/197 [==============================] - 2s 11ms/step - loss: 0.1106 - acc: 0.9683 - val_loss: 1.4476 - val_acc: 0.7046\n",
            "Epoch 17/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.1077 - acc: 0.9679 - val_loss: 1.4725 - val_acc: 0.7050\n",
            "Epoch 18/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.1087 - acc: 0.9671 - val_loss: 1.5231 - val_acc: 0.7002\n",
            "Epoch 19/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.1074 - acc: 0.9679 - val_loss: 1.5480 - val_acc: 0.6961\n",
            "Epoch 20/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.1027 - acc: 0.9701 - val_loss: 1.4334 - val_acc: 0.7128\n",
            "Epoch 21/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.1135 - acc: 0.9674 - val_loss: 1.4784 - val_acc: 0.7058\n",
            "Epoch 22/50\n",
            "197/197 [==============================] - 2s 13ms/step - loss: 0.0986 - acc: 0.9676 - val_loss: 1.4777 - val_acc: 0.7035\n",
            "Epoch 23/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.1030 - acc: 0.9677 - val_loss: 1.4291 - val_acc: 0.7117\n",
            "Epoch 24/50\n",
            "197/197 [==============================] - 2s 11ms/step - loss: 0.0988 - acc: 0.9682 - val_loss: 1.4549 - val_acc: 0.7106\n",
            "Epoch 25/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0984 - acc: 0.9683 - val_loss: 1.5688 - val_acc: 0.6987\n",
            "Epoch 26/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0997 - acc: 0.9687 - val_loss: 1.4382 - val_acc: 0.7158\n",
            "Epoch 27/50\n",
            "197/197 [==============================] - 2s 11ms/step - loss: 0.0980 - acc: 0.9669 - val_loss: 1.5295 - val_acc: 0.7028\n",
            "Epoch 28/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0940 - acc: 0.9679 - val_loss: 1.5165 - val_acc: 0.7039\n",
            "Epoch 29/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0912 - acc: 0.9679 - val_loss: 1.5460 - val_acc: 0.7039\n",
            "Epoch 30/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0928 - acc: 0.9672 - val_loss: 1.4567 - val_acc: 0.7132\n",
            "Epoch 31/50\n",
            "197/197 [==============================] - 2s 11ms/step - loss: 0.0941 - acc: 0.9672 - val_loss: 1.4406 - val_acc: 0.7124\n",
            "Epoch 32/50\n",
            "197/197 [==============================] - 2s 11ms/step - loss: 0.0898 - acc: 0.9687 - val_loss: 1.5121 - val_acc: 0.7046\n",
            "Epoch 33/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0900 - acc: 0.9676 - val_loss: 1.5332 - val_acc: 0.7076\n",
            "Epoch 34/50\n",
            "197/197 [==============================] - 2s 13ms/step - loss: 0.0918 - acc: 0.9683 - val_loss: 1.4986 - val_acc: 0.7106\n",
            "Epoch 35/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0889 - acc: 0.9680 - val_loss: 1.5003 - val_acc: 0.7095\n",
            "Epoch 36/50\n",
            "197/197 [==============================] - 2s 11ms/step - loss: 0.0892 - acc: 0.9680 - val_loss: 1.5093 - val_acc: 0.7076\n",
            "Epoch 37/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0883 - acc: 0.9685 - val_loss: 1.5214 - val_acc: 0.7013\n",
            "Epoch 38/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0920 - acc: 0.9668 - val_loss: 1.4591 - val_acc: 0.7113\n",
            "Epoch 39/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0843 - acc: 0.9680 - val_loss: 1.4555 - val_acc: 0.7173\n",
            "Epoch 40/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0827 - acc: 0.9687 - val_loss: 1.4393 - val_acc: 0.7180\n",
            "Epoch 41/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0866 - acc: 0.9676 - val_loss: 1.4769 - val_acc: 0.7135\n",
            "Epoch 42/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0853 - acc: 0.9683 - val_loss: 1.5059 - val_acc: 0.7106\n",
            "Epoch 43/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0851 - acc: 0.9677 - val_loss: 1.4905 - val_acc: 0.7069\n",
            "Epoch 44/50\n",
            "197/197 [==============================] - 2s 11ms/step - loss: 0.0802 - acc: 0.9669 - val_loss: 1.6018 - val_acc: 0.7032\n",
            "Epoch 45/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0767 - acc: 0.9695 - val_loss: 1.5698 - val_acc: 0.7046\n",
            "Epoch 46/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0807 - acc: 0.9671 - val_loss: 1.5671 - val_acc: 0.7032\n",
            "Epoch 47/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0765 - acc: 0.9699 - val_loss: 1.5974 - val_acc: 0.7002\n",
            "Epoch 48/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0799 - acc: 0.9690 - val_loss: 1.5233 - val_acc: 0.7069\n",
            "Epoch 49/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0791 - acc: 0.9676 - val_loss: 1.5685 - val_acc: 0.7024\n",
            "Epoch 50/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0756 - acc: 0.9695 - val_loss: 1.5752 - val_acc: 0.7035\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShvVFrfYjjjR"
      },
      "source": [
        "# evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3oX5WUmdNuA",
        "outputId": "51a973b7-0dd4-47f9-94b9-1da4ff756f44"
      },
      "source": [
        "model.evaluate(pad_x_train, y_train)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "281/281 [==============================] - 1s 3ms/step - loss: 0.5078 - acc: 0.8955\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5077683925628662, 0.8954575657844543]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIBeheiOjWXD",
        "outputId": "ba5d5c73-df86-4046-bdd2-d3a41f0d1b67"
      },
      "source": [
        "pad_x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=500)\n",
        "len(x_test[20]), len(pad_x_test[20])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(103, 500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lc_sPr-wjZpw",
        "outputId": "e495610c-2f53-41c5-d118-089a75e52ddd"
      },
      "source": [
        "model.evaluate(pad_x_test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "71/71 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lSVcIh2jgn4"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}